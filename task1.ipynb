{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Assessment 1\n",
    "#### Student Name: PRASHANT JAJORIA\n",
    "#### Student ID: 31187366\n",
    "\n",
    "Date: 13/09/2020\n",
    "\n",
    "Environment: Python 3.7.4 and Anaconda 4.8.4 (64-bit)\n",
    "\n",
    "Libraries used:\n",
    "* langid - for finding English tweets, included in Anaconda Python 3.7.4\n",
    "* re - for regular expression, included in Anaconda Python 3.7.4\n",
    "* os - for reading and writing file, included in Anaconda Python 3.7.4\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "The main goal of this assignment is to extract data from semi-structured text files, which forms the basis of Text analysis. A total of 2421 `.txt` files have been provided, containing data about COVID-19 related tweets. The main objective in this task is to get the information about the tweets into a structured `XML` format.\n",
    "\n",
    "Following are the requirement of the task:\n",
    "1. Extract unique tweet ID with their corresponding text and the date on which the tweet was created.\n",
    "2. Only English tweets should be included in the `XML` file.\n",
    "3. The data should be stored in provided `XML` structure. \n",
    "\n",
    "A step by step explanation for of completing the requirements will be explained in the following code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import langid as lg\n",
    "from os import listdir\n",
    "from os.path import isfile, join, dirname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the name of all input .txt files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start analyzing the tweets we need to get the names of all the `.txt` files. For this this I define a function named `get_name_input_files()`. This function returns a list of name of all the `.txt` files containing the data about the tweets. \n",
    "It gets all `.txt` filename` stored in the directory named **part1** relative to the current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is the expected directory structure for the code to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`D:\\monash\\sem2\\fit5196\\assignment1\\part1`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**assignment1** : Directory where the `task1_31187366.py` file is stored\n",
    "\n",
    "**part1** : Directory with all the `.txt` files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `os.path.dirname(__file__)` function gets the directory name where the python script is running. Then we add the directory **part1**, as all the inuput `.txt` files are stored in that directory. Using `listdir()` passing the directory name where the `.txt` files are stored, we get the list of files. Using list comprehension here `[f for f in listdir(dir_name) if isfile(join(dir_name, f)) and f.endswith('.txt')]` to make a list of names of all the `.txt` files in **part1** directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_input_files():\n",
    "    '''\n",
    "        Return type : List of names of txt files\n",
    "    '''\n",
    "    \n",
    "    # variable to store the directory name\n",
    "    dir_name = \"\"\n",
    "    \n",
    "    # variable to store the path of txt files\n",
    "    list_txt_files = []\n",
    "    \n",
    "    # as all the input .txt files are in 'part1' directory, append 'part1' at the end\n",
    "    dir_name = os.path.dirname(os.path.realpath('__file__')) + \"/part1/\"\n",
    "    \n",
    "    # List of txt file names in the 'part1' directory\n",
    "    list_txt_files = [f for f in listdir(dir_name) if isfile(join(dir_name, f)) and f.endswith('.txt')]\n",
    "    \n",
    "    return list_txt_files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Read all the .txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function named `read_txt_files()` with parameter being a list of names of txt files. Open each file which is in the list using the `open()` function and read the lines of `.txt` file using `readlines()` functions. Store all the read lines in a dictionary, with key being the filename and value is the lines read from that file. Finally return the dictionary which has the file content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_files(list_txt_files):\n",
    "    '''\n",
    "        Parameter : List of txt file names\n",
    "        Return type : Dictionary containing the content of txt files\n",
    "    '''\n",
    "    \n",
    "    # defining variable to store the content of txt files.\n",
    "    dict_file_content = {}\n",
    "    \n",
    "    # variable to store the directory path of txt files\n",
    "    # append 'path1' as all the input .txt files are in 'part1' directory\n",
    "    dir_name= os.path.dirname(os.path.realpath('__file__')) + \"/part1/\"\n",
    "    \n",
    "    # loop through all the filenames in the list\n",
    "    for file_name in list_txt_files:\n",
    "        \n",
    "        # open each file in 'read' mode using 'UTF-8' encoding\n",
    "        with open(dir_name + file_name, 'r', encoding = \"utf-8\") as f:\n",
    "            \n",
    "            #read the content of each file and store as string in a dictionary\n",
    "            dict_file_content[file_name] = \"\"\n",
    "            \n",
    "            # read all the lines\n",
    "            for line in f.readlines():\n",
    "                \n",
    "                # key of dictionary is the filename\n",
    "                dict_file_content[file_name] = dict_file_content[file_name] + line\n",
    "    \n",
    "    return dict_file_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Driver function to get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function named `get_results()` which acts as the starting point of all the process of data extraction. It firstly calls the `get_name_input_files()` which returns a list of `.txt` filenames. Once we have the name of `.txt` files, it calls the `read_txt_files()` function which returns a dictionary with key being the filename and value being the text of the file. Then the `extract_data()` function is called passing the **filename** and **content** of each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results():\n",
    "    '''\n",
    "    Driver function to carry out all the oprations of getting the final results\n",
    "    '''\n",
    "    \n",
    "    # get the names of txt files\n",
    "    list_txt_files = get_name_input_files()\n",
    "    \n",
    "    #read the content of each file and store as string in a dictionary\n",
    "    dict_file_content = read_txt_files(list_txt_files)\n",
    "    \n",
    "    # to store of count of files processed\n",
    "    count = 1\n",
    "    \n",
    "    # for each file extract the data\n",
    "    for each_file in list_txt_files:\n",
    "        \n",
    "        # get the file content corresponding to the file name\n",
    "        file_content = dict_file_content[each_file]\n",
    "        \n",
    "        # MAGIC FUNCTION\n",
    "        # pass this file data to start analysing the tweets\n",
    "        extract_data(each_file,file_content)\n",
    "        \n",
    "        # print number of files processed\n",
    "        print( str( round(count/len( list_txt_files ),4)*100 ) + \" % Files processed\" )\n",
    "        \n",
    "        count = count + 1\n",
    "        \n",
    "    tweets_to_xml(day_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Defining helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_tweet_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function named `get_tweet_id()` to extract the **ID** from the given tweet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression used is **(\\d{19})**. \n",
    "- () indicates a capturing group. \n",
    "- \\d indicates any digit from [0-9]\n",
    "- \\d{19} matches 19 digits which occur together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_tweet_id(tweet_data):\n",
    "    '''\n",
    "    Function to get the tweet Id\n",
    "    Parameter : String\n",
    "    Return type : List \n",
    "    '''\n",
    "    \n",
    "    return re.findall(r'(\\d{19})',tweet_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_tweet_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function named `get_tweet_date()` to extract the **DATE** from the given tweet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression used is  **(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}.\\d{3}Z)**. \n",
    "- () indicates a capturing group. \n",
    "- \\d indicates any digit from [0-9]\n",
    "- \\d(4) indicates 4 digits occuring together. Similarly \\d{2} indicates two digits together.\n",
    "\n",
    "As the date is in the format YYYY-MM-DDTHH:MM:SS.SSSZ, the regex capture the date, month and year seperated by hyphens(-). Similarly the time is seperated by colon(:). And the **T** is used to denote the start of time and **Z** denote the end of date time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_date(tweet_data):\n",
    "    '''\n",
    "    Function to get the Tweet date\n",
    "    Parameter : String\n",
    "    Return type : List\n",
    "    '''\n",
    "    \n",
    "    return re.findall(r'(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}.\\d{3}Z)',tweet_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_tweet_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function named get_tweet_text() to extract the TEXT from the given tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text appears in different format in the given `.txt` files. So a single Regular expression cannot capture the text for all the files. We need to conditionally use different Regular expressions to capture the Text for all the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the below Regular expresions uses lazy binding i.e. `.*?` to capture the text\n",
    "- `\"text\":\"(.*?)\"` - In this re the Tweet text starts with \"text\" and ends with \".\n",
    "- `\"(.*?)\",\"created_at` - In this re the Tweet text starts \" and ends with \",\"created_at\n",
    "- `\"text\":\"(.*?)\",\"id\"` - In this re the Tweet text starts \"text\":\" and ends with \",\"id\"\n",
    "- `\"text\":([^\\\\].*)` - In this re the Tweet text starts \"text\":. Also here text can have \\ because it is escaped in the character set `[^\\\\]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_text(tweet_data):\n",
    "    '''\n",
    "    Function to get the tweet text\n",
    "    Parameter : String\n",
    "    '''\n",
    "    \n",
    "    # using this re first\n",
    "    re_result_text =  re.findall(r'\"text\":\"(.*?)\"',tweet_data,re.DOTALL)\n",
    "    \n",
    "    \n",
    "    # as the previous re used \"text\" the lenght of list is zero\n",
    "    # so need a new re to get the text\n",
    "    if len(re_result_text) == 0 :        \n",
    "        return re.findall(r'\"(.*?)\",\"created_at',tweet_data,re.DOTALL)\n",
    "    \n",
    "    # if the previous re could only captured a \\ then go here\n",
    "    elif re_result_text[0] == \"\\\\\" :\n",
    "        \n",
    "        # in this re the text ends with \"created_at\"\n",
    "        re_result_text = re.findall(r'\"(.*?)\",\"created_at',tweet_data,re.DOTALL)\n",
    "        \n",
    "        # if still no data is captured then go here\n",
    "        if not re_result_text:\n",
    "            \n",
    "            # in this re the text starts with \"text\" and ends with \"id\"\n",
    "            re_result_text =  re.findall(r'\"text\":\"(.*?)\",\"id\"',tweet_data,re.DOTALL)\n",
    "            \n",
    "            # if no result is captured\n",
    "            if not re_result_text:\n",
    "                \n",
    "                # in this re the text cannot contain \\\n",
    "                return re.findall(r'\"text\":([^\\\\].*)',tweet_data,re.DOTALL)\n",
    "            else:\n",
    "                return re_result_text\n",
    "        else:       \n",
    "            return re_result_text\n",
    "    else:\n",
    "        return re_result_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is_english_tweet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function named `is_english_tweet()` to classify if tweet is in English. It uses the `classify()` function from langid pacakge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english_tweet(tweet_text):\n",
    "    '''\n",
    "    Function to calssify tweet\n",
    "    Return type: Boolean\n",
    "    '''\n",
    "    \n",
    "    # tuple has value 'en' for English\n",
    "    if lg.classify(tweet_text)[0] == 'en':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Defining variables to store the Tweet data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the main variables storing all the tweets data.\n",
    "\n",
    "- `tweets` : This is a dictionary mapping each Tweet ID with its corresponding text.\n",
    "- `day_tweets` : This is a dictionary mapping the date and the List of tweet ID for that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping of id and tweet text\n",
    "tweets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of tweets of a day\n",
    "day_tweets = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Add mapping for the tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function named `add_tweet()` to add the Tweet to dictionary which has all the Tweet Ids mapped to the Tweet text.\n",
    "Using a dictionary ensures that we don not have repeated Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tweet(tweet_id,tweet_text):\n",
    "    '''\n",
    "    Function : Add to dictionary named 'tweets' which maps all the Tweet ID to their text.\n",
    "    '''\n",
    "    \n",
    "    if tweet_id not in tweets:\n",
    "        tweets[tweet_id] = tweet_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Group the Tweets of same date together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function named `collect_tweets()` to keep the Tweet of same date together in the dictionary `day_tweets`. This function first checks if we have a corresponding mapping for that date in our `day_tweets` dictionary. If there is already a list for that date, then the coming Tweed ID is added to that list. Else a new mapping is made in `day_tweets` for the date and a new list is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tweets(tweet_id,tweet_date):\n",
    "    '''\n",
    "    Function : Store thetweet of same date together\n",
    "    Parameter : tweet_id - Id of tweet\n",
    "                tweet_date - Date on which the tweet was created\n",
    "    '''\n",
    "    \n",
    "    # Tweet is of a new date\n",
    "    if tweet_date not in day_tweets:\n",
    "        day_tweets[tweet_date] = [tweet_id]\n",
    "    \n",
    "    # tweet is of an existing date\n",
    "    else:\n",
    "        list_tweet_ids = day_tweets[tweet_date]\n",
    "        list_tweet_ids.append(tweet_id)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Extarct the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function named `extract_data()` to extract every Tweet information i.e. Text, ID and date of each tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter of the `extract_data()`:\n",
    "\n",
    "`file_name` : This is the name of a single `.txt` file out of all the 2421 files.\n",
    "\n",
    "`file_content` : It is the concatinated String containing all the tweets of a file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function gets the concatinated String of a `.txt` file and captures the Tweet text, date and ID using the follwoing Regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`{\"id\":(\".*?\")},|{\"text\":(\".*?\")},|{\"created_at\":(\".*?\")},`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I use alternation i.e. `|` to capture the whole tweet information. As the format in which data about Tweet is stored is different for some files, we need 3 regular expressions to capture the data.\n",
    "\n",
    "- `{\"id\":(\".*?\")},` : This regular expression captures the data from file in which the tweet data starts with `{\"id\":` and ends with `},`. `(\".*?\")`. Basicaly it gets captures the Text, ID and date created for each tweet. In this Regular expression I use lazy binding i.e. `.*?` to match as little as possible. Otherwise it will match the whole file.\n",
    "\n",
    "- `{\"text\":(\".*?\")},` :  This regular expression captures the data from file in which the tweet data starts with `{\"text\":` and ends with `},`. Basicaly it gets captures the Text, ID and date created for each tweet. Again lazy binding is used to capture data of single tweet.\n",
    "\n",
    "- `{\"created_at\":(\".*?\")},` : This regular expression captures the data from file in which the tweet data starts with `{\"created_at\":` and ends with `},`. This will capture the Text, ID and date created for each tweet. Lazy binding used to match little as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ID, text and date of each tweet captured by the regular expression is then passed to the helper functions i.e. `get_tweet_text()`, `get_tweet_id()` and `get_tweet_date()` to capture the Text, ID and date of each tweet from the whole string.\n",
    "\n",
    "THe text of the tweet is then passed to `is_english_tweet()` function to see if the tweet was in English.\n",
    "\n",
    "If the Tweet is in English, then `add_tweet()` is used to add the tweet to the common dictionary `tweets` with its corresponding tweet ID.\n",
    "\n",
    "Also, for English tweets, the `collect_tweets()` is called to add it to common dictionary of each day `day_tweets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_name, file_content):\n",
    "    '''\n",
    "    Function to get the Tweet text, date and ID\n",
    "    Parameter : file_name - String\n",
    "                file_content - String\n",
    "    '''\n",
    "    \n",
    "    # use re.findal all the match the regular expression pattern\n",
    "    # re.DOTALL flag to include newline from the string.\n",
    "    re_result_data = re.findall(r'{\"id\":(\".*?\")},|{\"text\":(\".*?\")},|{\"created_at\":(\".*?\")},', file_content,re.DOTALL)\n",
    "    \n",
    "    # loop throuht the list of result returned by re.findall()\n",
    "    for each_tweet_data in re_result_data:\n",
    "    \n",
    "        # first expression catures the data\n",
    "        if each_tweet_data[0]:\n",
    "            # get the tweet text\n",
    "            tweet_text = get_tweet_text(each_tweet_data[0])[0]\n",
    "            # get the tweet ID\n",
    "            tweet_id = get_tweet_id(each_tweet_data[0])[0]\n",
    "            # get the Date\n",
    "            tweet_date = get_tweet_date(each_tweet_data[0])[0]\n",
    "            \n",
    "            # process only english tweets\n",
    "            if is_english_tweet(tweet_text):\n",
    "                \n",
    "                # add mapping of tweet and its ID\n",
    "                add_tweet(tweet_id,tweet_text)\n",
    "                # store tweets of same date together\n",
    "                collect_tweets(tweet_id,tweet_date[:10])\n",
    "        \n",
    "        # second expression catures the data    \n",
    "        elif each_tweet_data[1]:\n",
    "            \n",
    "            # get the tweet text\n",
    "            tweet_text = get_tweet_text(each_tweet_data[1])[0]\n",
    "            # get the tweet ID\n",
    "            tweet_id = get_tweet_id(each_tweet_data[1])[0]\n",
    "            # get the Date\n",
    "            tweet_date = get_tweet_date(each_tweet_data[1])[0]\n",
    "            \n",
    "            # process only english tweets\n",
    "            if is_english_tweet(tweet_text): \n",
    "                # add mapping of tweet and its ID\n",
    "                add_tweet(tweet_id,tweet_text)\n",
    "                # store tweets of same date together\n",
    "                collect_tweets(tweet_id,tweet_date[:10])\n",
    "        \n",
    "        # third expression catures the data\n",
    "        elif each_tweet_data[2]:\n",
    "            \n",
    "            # get the tweet text\n",
    "            tweet_text = get_tweet_text(each_tweet_data[2])[0]\n",
    "            # get the tweet ID\n",
    "            tweet_id = get_tweet_id(each_tweet_data[2])[0]\n",
    "            # get the Date\n",
    "            tweet_date = get_tweet_date(each_tweet_data[2])[0]\n",
    "            \n",
    "            # process only english tweets\n",
    "            if is_english_tweet(tweet_text):\n",
    "                # add mapping of tweet and its ID\n",
    "                add_tweet(tweet_id,tweet_text)\n",
    "                # store tweets of same date together\n",
    "                collect_tweets(tweet_id,tweet_date[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.Function to write to XML file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets_to_xml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function named `tweets_to_xml()` to write the final Tweet text, ID and date of each tweet to the XML file.\n",
    "\n",
    "First we open a new file object for file in mode write binary `wb` named file_object.\n",
    "\n",
    "Writing the XML encoding and declaration to the file.\n",
    "\n",
    "`<?xml version=\"1.0\" encoding=\"UTF-8\"?>`\n",
    "\n",
    "Then writing the data in the following XML structure.\n",
    "\n",
    "`\n",
    "<data>\n",
    "    <tweets>\n",
    "        <tweet> </tweet>\n",
    "    </tweets>\n",
    "</data>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iteratively loop through each date and the Tweets using the `day_tweets` dictionary, for each date to write to the file. For each date, since the tweet ID is stored in a list we loop throught the list and get the text mapped for each ID from `tweets`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to replace the newline character i.e. replace `\\\\n` with `\\n`, since Python escapes the `\\` for us "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_to_xml(day_tweets):\n",
    "    \n",
    "    '''\n",
    "    Function to write Tweet Text, ID and date to the XML file\n",
    "    Parameter : Dictionary having key as Date and value as List of Tweet IDs for that date\n",
    "    '''\n",
    "    \n",
    "    file_object = open(\"output_tweets_new123.xml\",\"wb\")\n",
    "    \n",
    "    xml_dec = \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n\"\n",
    "    file_object.write(xml_dec.encode('utf-8'))\n",
    "    print(xml_dec)\n",
    "    \n",
    "    xml_data_tag_open = \"<data>\\n\"\n",
    "    file_object.write(xml_data_tag_open.encode('utf-8'))\n",
    "    print(xml_data_tag_open)\n",
    "    \n",
    "    for date , list_ids in day_tweets.items() :\n",
    "        xml_tweets_tag_open = \"<tweets date=\\\"\" + date + \"\\\">\\n\"\n",
    "        file_object.write(xml_tweets_tag_open.encode('utf-8'))\n",
    "        print(xml_tweets_tag_open)\n",
    "        \n",
    "        for tweet_id in list_ids:\n",
    "                tweet_text = tweets[tweet_id]\n",
    "                tweet_text = tweet_text.replace(\"\\\\n\",\"\\n\")\n",
    "                \n",
    "                if tweet_text == \"\\\\\":\n",
    "                    print(tweet_id)\n",
    "                \n",
    "                if not is_tweet_printed(tweet_id):\n",
    "                \n",
    "                    xml_tweet_tag_open = \"<tweet id=\\\"\" + tweet_id + \"\\\">\" + tweet_text + \"</tweet>\\n\"\n",
    "                    file_object.write(xml_tweet_tag_open.encode('utf-8'))\n",
    "                    \n",
    "                    print(xml_tweet_tag_open)\n",
    "                \n",
    "        xml_tweets_tag_close = \"</tweets>\\n\"\n",
    "        file_object.write(xml_tweets_tag_close.encode('utf-8'))\n",
    "        print(xml_tweets_tag_close)\n",
    "        \n",
    "    xml_data_tag_close = \"</data>\"\n",
    "    file_object.write(xml_data_tag_close.encode('utf-8'))\n",
    "    print(xml_data_tag_close)\n",
    "    \n",
    "    file_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Function to check if the Tweet is already written to XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function named is_tweet_printed() to check if the Tweet data is already written to XML. If the it is written to XML then the function returns `True` else it adds the Tweet ID to a list of tweets that are written to XML file `list_tweets_written` and returns `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tweets written to XML\n",
    "list_tweets_written = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_tweet_printed(tweet_id):\n",
    "    '''\n",
    "    Function to check if the Tweet has been writtent to the XML file\n",
    "    Parameter : ID\n",
    "    Returns : True - if Tweet already written to XML file\n",
    "              False - if Tweet not written to XML\n",
    "    '''\n",
    "    \n",
    "    if tweet_id in list_tweets_written:\n",
    "        return True\n",
    "    else:\n",
    "        list_tweets_written.append(tweet_id)        \n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 Invoke the Driver function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have all the functions and files in place. Lets invoke the driver function `get_results()` to start the Tweet processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** : Run all the previous code cells to get the final XML result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In case of following Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOPub data rate exceeded.\n",
    "\n",
    "The notebook server will temporarily stop sending output\n",
    "\n",
    "to the client in order to avoid crashing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relaunch Jupyter Notebook using following command**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary\n",
    "This assessment helps to build up the knowledge of processing semi-structured data and extract data, which is he fundamental step for Text analysis. The main objective achieved are as follows:\n",
    "\n",
    "- **Parsing Text files to extract from Raw data** : By using the `listdir`, `dirname` and `isfile` functions from `os` package, along with inbuilt python `open` function, it was possible to read all the `.txt` files from a particular directory.\n",
    "\n",
    "- **Formulating Regular Expressions** : Developing Regular expression to capture the Tweet text, ID and Date helped to build upon the knowledge of forming Regular expressions. Using `findall` method from `re` package helped to capture a list of data using the defined regular expression.\n",
    "\n",
    "- **Remove Non-English Tweets** : Using `langid` package it was possible to check if the text of Tweet was in English or not. This was achieved by using the `classify` function. \n",
    "\n",
    "- **Writing data to XML file** : Using the inbuilt python `write` function it was possible to write the Tweet text, ID and date to `XML` format.\n",
    "\n",
    "- **Manipulating Python Data structures**: For successful completion of this task knowledge of manipulating basic Data Structures like `list`, `tuple` and `dictionary` was important. Using dictionary functions like `items` and `keys` was helpfult for iteration. Also the `in` operator was needed for various condition check.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. References\n",
    "- Built-in Functions — Python 3.8.6rc1 documentation. (2020). Retrieved 15 September 2020, from https://docs.python.org/3/library/functions.html#open\n",
    "- os.path — Common pathname manipulations — Python 3.8.6rc1 documentation. (2020). Retrieved 15 September 2020, from https://docs.python.org/3/library/os.path.html\n",
    "- re — Regular expression operations — Python 3.8.6rc1 documentation. (2020). Retrieved 15 September 2020, from https://docs.python.org/3/library/re.html\n",
    "- Regex Cheat Sheet. (2020). Retrieved 15 September 2020, from https://www.rexegg.com/regex-quickstart.html\n",
    "- langid. (2020). Retrieved 15 September 2020, from https://pypi.org/project/langid/1.1dev/\n",
    "- Regular Expression (Regex) Tutorial. (2020). Retrieved 15 September 2020, from https://www3.ntu.edu.sg/home/ehchua/programming/howto/Regexe.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
